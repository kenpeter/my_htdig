<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
  <head>
	<title>
	  ht://Dig: Features and System requirements
	</title> 
        <link rel="stylesheet" href="htdig.css">
  </head>
  <body bgcolor="#eef7ff">
	<h1>
	  Features and System requirements
	</h1>
	<p>
	  ht://Dig Copyright &copy; 1995-2002 <a href="THANKS.html">The ht://Dig Group</a><br>
	  Please see the file <a href="COPYING">COPYING</a> for
	  license information.
	</p>
	<hr noshade>
	<h2>
	  Features
	</h2>
	<p>
	  Here are some of the major features of ht://Dig. They are in
	  no particular order.
	</p>
	<blockquote>
	<dl>
	  <dt>
		<strong><img src="bdot.gif" width=9 height=9 alt="*"> Intranet searching</strong>
	  </dt>
	  <dd>
		ht://Dig has the ability to search through many servers
		on a network by acting as a WWW browser.
	  </dd>
	  <dt>
		<strong><img src="bdot.gif" width=9 height=9 alt="*"> It is free</strong>
	  </dt>
	  <dd>
		The whole system is released under the
		<a href="COPYING">GNU General Public License</a>
	  </dd>
	  <dt>
		<strong><img src="bdot.gif" width=9 height=9 alt="*"> Robot exclusion is supported</strong>
	  </dt>
	  <dd>
		The <a href="http://info.webcrawler.com/mak/projects/robots/norobots.html">
		Standard for Robot Exclusion</a> is supported by
		ht://Dig.
	  </dd>
	  <dt>
		<strong><img src="bdot.gif" width=9 height=9 alt="*"> Boolean expression searching</strong>
	  </dt>
	  <dd>
		Searches can be arbitrarily complex using boolean
		expressions.
	  </dd>
	  <dt>
		<strong><img src="bdot.gif" width=9 height=9 alt="*"> Configurable search results</strong>
	  </dt>
	  <dd>
		The output of a search can easily be tailored to your
		needs by means of providing HTML templates.
	  </dd>
	  <dt>
		<strong><img src="bdot.gif" width=9 height=9 alt="*"> Fuzzy searching</strong>
	  </dt>
	  <dd>
		Searches can be performed using various configurable
		algorithms. Currently the following algorithms are
		supported (in any combination):
		<ul>
		  <li>
			exact
		  </li>
		  <li>
			soundex
		  </li>
		  <li>
			metaphone
		  </li>
		  <li>
			common word endings (stemming)
		  </li>
		  <li>
			synonyms
		  </li>
		  <li>
			accent stripping
		  </li>
		  <li>
			substring and prefix
		  </li>
		</ul>
	  </dd>
	  <dt>
		<strong><img src="bdot.gif" width=9 height=9 alt="*"> Searching of HTML and text files</strong>
	  </dt>
	  <dd>
		Both HTML documents and plain text files can be
		searched. Searching of other file types will be
		supported in future versions.
	  </dd>
	  <dt>
		<strong><img src="bdot.gif" width=9 height=9 alt="*"> Keywords can be added to HTML
		documents</strong>
	   </dt>
	  <dd>
		Any number of keywords can be added to HTML documents
		which will not show up when the document is viewed.
		This is used to make a document more like to be found
		and also to make it appear higher in the list of
		matches.
	  </dd>
	  <dt>
		<strong><img src="bdot.gif" width=9 height=9 alt="*"> Email notification of expired
		documents</strong>
	  </dt>
	  <dd>
		Special meta information can be added to HTML documents
		which can be used to notify the maintainer of those
		documents at a certain time. It is handy to get
		reminded when to remove the "New" images from a certain
		page, for example.
	  </dd>
	  <dt>
		<strong><img src="bdot.gif" width=9 height=9 alt="*"> A Protected server can be indexed</strong>
	  </dt>
	  <dd>
		ht://Dig can be told to use a specific username and
		password when it retrieves documents. This can be used
		to index a server or parts of a server that are
		protected by a username and password.
	  </dd>
	  <dt>
		<strong><img src="bdot.gif" width=9 height=9 alt="*"> Searches on subsections of the
		database</strong>
	  </dt>
	  <dd>
		It is easy to set up a search which only returns
		documents whose URL matches a certain pattern. This
		becomes very useful for people who want to make their
		own data searchable without having to use a separate
		search engine or database.
	  </dd>
	  <dt>
		<strong><img src="bdot.gif" width=9 height=9 alt="*"> Full source code included</strong>
	  </dt>
	  <dd>
		The search engine comes with full source code. The
		whole system is released under the terms and conditions
		of the <a href="COPYING">GNU Public License version
		2.0</a>
	  </dd>
	  <dt>
		<strong><img src="bdot.gif" width=9 height=9 alt="*"> The depth of the search can be limited</strong>
	  </dt>
	  <dd>
		Instead of limiting the search to a set of machines, it
		can also be restricted to documents that are a certain
		number of "mouse-clicks" away from the start document.
	  </dd>
	  <dt>
		<strong><img src="bdot.gif" width=9 height=9 alt="*"> Full support for the ISO-Latin-1 character
		set</strong>
	  </dt>
	  <dd>
		Both SGML entities like '&amp;agrave;' and ISO-Latin-1
		characters can be indexed and searched.
	  </dd>
	</dl>
	</blockquote>
	<hr size="4" noshade>
	<h1>
	  Requirements to build ht://Dig
	</h1>
	<p>
	  ht://Dig was developed under Unix using C++.
	</p>
	<p>
	  For this reason, you will need a Unix machine, a C compiler
	  and a C++ compiler. (The C compiler is needed to compile some
	  of the GNU libraries)
	</p>
	<p>
	  Unfortunately the developers only have access to a couple of
	  different Unix machines. Most development is done on Linux
	  systems with gcc/g++, but ht://Dig has been tested on these
	  machines (and compilers):
	</p>
	<ul>
	  <li>
		Sun Solaris SPARC 2.X (using gcc/g++)
	  </li>
	  <li>
		Sun SunOS 4.1.4 SPARC (using gcc/g++ 2.7.0)
	  </li>
	  <li>
		HP/UX 10.X (using gcc/g++)
	  </li>
	  <li>
		IRIX 5.3 and 6.X (SGI C++ compiler.)
	  </li>
	  <li>
		Most Linux Distributions (using gcc/g++)
	  </li>
	  <li>
	        Most BSD platforms, including BSDI and Mac OS X (using gcc/g++)
          </li>
	</ul>
	There are reports of ht://Dig working on a number of other
	platforms. If you've compiled ht://Dig on a platform that is
	not listed here, please let the developers know via the <a
	href="mailto:htdig-dev@lists.sourceforge.net">htdig-dev</a>
	mailing list.
	<h3>
	  libstdc++
	</h3>
	<p>
	  If you plan on using g++ to compile ht://Dig, you have to make
	  sure that libstdc++ has been installed. For older versions
	  of gcc/g++ (2.8.X and prior), libstdc++ is a
	  separate package from gcc/g++. You can get libstdc++ from the
	  <a href="ftp://ftp.gnu.org/gnu/">GNU software archive</a>.
	</p>
	<h3>
	  GNU-style (Berkeley) 'make'
	</h3>
	<p>
	  The building relies heavily on the make program. The problem
	  with this is that not all make programs are the same. The
	  requirement for the make program is that it understands the
	  'include' statement as in
	</p>
	<blockquote>
	  <code>include somefile</code>
	</blockquote>
	<p>
	  The Berkeley 4.4 make program supplied in many BSD-style
	  systems doesn't use this syntax, instead
	  it wants
	</p>
	<blockquote>
	  <code>.include "somefile"</code>
	</blockquote>
	<p>
	  and hence it cannot be used to build ht://Dig. Many systems
	  include a &quot;gmake&quot; command that will work instead.
	</p>
	<p>
	  If your make program doesn't understand the right 'include'
	  syntax, it is best if you get and install
	  <a href="ftp://ftp.gnu.org/gnu/make/">GNU make</a> before you try
	  to compile everything. The alternative is to change all the
	  Makefiles.
	</p>
	<hr noshade>
	<h1>
	  Disk space requirements
	</h1>
	<p>
	  The search engine will require lots of disk space to store
	  its databases. Unfortunately, there is no exact formula to
	  compute the space requirements. It depends on the number of
	  documents you are going to index but also on the various
	  options you use. To give you an idea of the space
	  requirements, here is what I have deduced from our own
	  database size at San Diego State University.
	</p>
	<p>
	  If you keep around the wordlist database (for update digging
	  instead of initial digging) I found that multiplying the
	  number of documents covered by 12,000 will come pretty close
	  to the space required.
	</p>
	<p>
	  We have about 13,000 documents:
	</p>
<pre>
         13,000
         12,000 x
    -----------
    156,000,000
</pre>
	or about 150 MB.
	<p>
	  Without the wordlist database, the factor drops down to about
	  7500:
	</p>
<pre>
         13,000
          7,500 x
     ----------
     97,500,000
</pre>
	or about 93 MB.
	<p>
	  Keep in mind that we keep at most 50,000 bytes of each
	  document. This may seen a lot, but most documents aren't very
	  big and it gives us a big enough chunk to almost always show
	  an excerpt of the matches.
	</p>
	<p>
	  You may find that if you store most of each document, the
	  databases are almost the same size, or even larger than the
	  documents themselves! Remember that if you're storing a
	  significant portion of each document (say 50,000 bytes as
	  above), you have that requirement, plus the size of the word
	  database and all the additional information about each document
	  (size, URL, date, etc.) required for searching.
	</p>
	<hr size="4" noshade>

	Last modified: $Date: 2002/01/28 03:56:10 $

  </body>
</html>
